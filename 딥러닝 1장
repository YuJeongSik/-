{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"딥러닝 1장","provenance":[{"file_id":"https://github.com/codingalzi/dlp/blob/master/notebooks/dlp02_mathematical_building_blocks.ipynb","timestamp":1631764932354}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-niWhtbLwia-"},"source":["# 2장 신경망의 수학적 구성 요소"]},{"cell_type":"markdown","metadata":{"id":"r5v4QkdUwibB"},"source":["__감사말__: 프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 2장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다."]},{"cell_type":"markdown","metadata":{"id":"1bo7KSB9wibB"},"source":["__구글 코랩 설정__: '런타임 -> 런타임 유형 변경' 메뉴에서 GPU를 지정한다.\n","이후 아래 명령어를 실행했을 때 오류가 발생하지 않으면 필요할 때 GPU가 자동 사용된다.\n","\n","```\n","!nvidia-smi\n","```"]},{"cell_type":"markdown","metadata":{"id":"GEqeFtc_wibC"},"source":["## 2.1 신경망 소개"]},{"cell_type":"markdown","metadata":{"id":"xnHmwUChwibC"},"source":["**케라스로 MNIST 데이터셋 불러오기**\n","\n","- 손글씨 숫자 인식 용도 데이터셋: 70,000개의 샘플 포함\n","- 레이블(타깃): 0부터 9까지 10개의 범주(category, class)\n","- 훈련 세트\n","    - 모델 학습 용도\n","    - 샘플: 28x28 픽셀 크기의 이미지 60,000개\n","- 테스트 세트\n","    - 학습된 모델 성능 테스트 용도\n","    - 샘플: 28x28 픽셀 크기의 이미지 10,000개"]},{"cell_type":"code","metadata":{"id":"opCqZ0KVwibC"},"source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vleV6j8wibD","outputId":"dee2e035-8e2b-4c3b-dbcb-05e672880dc2"},"source":["train_images.shape  #3차원 모형"],"execution_count":null,"outputs":[{"data":{"text/plain":["(60000, 28, 28)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"nNhpqi1cwibE","outputId":"fcd559d3-bac2-4a7e-9f9d-f7100556c28c"},"source":["len(train_labels)"],"execution_count":null,"outputs":[{"data":{"text/plain":["60000"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"MbZrHdQ4wibF","outputId":"e51086a7-9482-42bb-cff3-ceb2910e7e3b"},"source":["train_labels #dtype=uint8 숫자 하나당 8비트를 쓴다는 뜻"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"ds6p5tLAwibF","outputId":"dc8ef49c-6c54-4948-f5a3-13f804eff3f8"},"source":["test_images.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(10000, 28, 28)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"fIBSSO7AwibG","outputId":"379d2362-4ca8-469e-8b36-e7bbd78228be"},"source":["len(test_labels)"],"execution_count":null,"outputs":[{"data":{"text/plain":["10000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"geNQSAdDwibG","outputId":"6d81e41f-b0c0-4420-81e5-146b37797d5a"},"source":["test_labels"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"iCjX3aLLwibG"},"source":["**신경망 구조 지정**\n","\n","아래 신경망의 구조는 다음과 같다.\n","\n","- 층(layer)\n","    - 2개의 Dense 층 사용\n","    - 입력 데이터로부터 __표현__(representation) 추출. 즉 입력 데이터를 새로운 표현으로 변환.\n","    - 일종의 __데이터 정제__를 위한 필터 역할 수행\n","- 층 연결\n","    - `Sequential` 모델 활용\n","    - 완전 연결(fully connected). 조밀(densely)하게 연결되었다고 함.\n","- 첫째 층\n","    - 512개의 유닛(unit) 사용. 즉 512개의 특성값으로 이루어진 표현 추출.\n","    - 활성화 함수(activation function): 렐루(relu) 함수\n","    - 렐루(relu) 함수는 음수는 모두 0으로 바꾸고 양수는 자기자신 그대로 보내는 함수이다\n","- 둘째 층\n","    - 10개의 유닛 사용. 10개의 범주를 대상으로 해당 범부에 속할 확률 계산.\n","        모든 확률의 합은 1.\n","    - 활성화 함수: 소프트맥스(softmax) 함수"]},{"cell_type":"markdown","metadata":{"id":"LItNC6e_w1GI"},"source":["텐서플로는 하나의 큰 파일이라고 생각하고 안에 keras와 같은 모듈이 있다고 생각하면 된다. 그 모듈 안에는 Sequential과 같은 클래스가 있다고 생각하면 된다"]},{"cell_type":"code","metadata":{"id":"2Ye2HdyOwibG"},"source":["#모델을 세팅\n","\n","from tensorflow import keras                    #tensorflow에 keras를 먼저 선언하고\n","from tensorflow.keras import layers             #모듈은 파이썬의 하나의 파일이라고 생각하면 됨\n","\n","\n","model = keras.Sequential([                      #설계도라고 생각하면 됨. 어떻게 훈련시킬지를 정하는 것\n","    layers.Dense(512, activation=\"relu\"),       #어떤 층을 사용할 것인지 정하는 곳. 여기서는 512개의 특성으로 층을 만듬\n","    layers.Dense(10, activation=\"softmax\")      \n","])\n","\n","#layers.Dense(512, activation=\"relu\")는 입력받은 '1차원' array를 받아서 [512]array로 훈련시켜서 내보내준다 > (28,28)인 2차원 array를 1차원 array인 [784]로 변환\n","#layers.Dense(10, activation=\"softmax\")는 윗층에서 받은 1차원 [784]를 [10]으로 변환\n","\n","#Sequential은 1차원으로만 인식 가능, Sequential은 클래스\n","#메소드마다 인식 가능한 차원이 다르므로 꼭 전처리 과정을 거쳐야함"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oX7ScfFwwibH"},"source":["**신경망 컴파일**\n","\n","구조가 지정된 신경망을 훈련이 가능한 모델로 만드는 과정이며 \n","아래 세 가지 사항이 지정되어야 한다.\n","\n","- __옵티마이저__(optimizer): 모델의 성능을 향상시키는 방향으로 가중치를 업데이트하는 알고리즘\n","- __손실 함수__(loss function): 훈련 중 성능 측정 기준\n","- __모니터링 지표__: 훈련과 테스트 과정을 모니터링 할 때 사용되는 평가 지표(metric).\n","    손실 함수값을 사용할 수도 있고 아닐 수도 있음. \n","    아래 코드에서는 정확도(accuracy)만 사용."]},{"cell_type":"code","metadata":{"id":"-N6IBNDhwibH"},"source":["#모델을 컴파일\n","\n","model.compile(optimizer=\"rmsprop\",            #optimizer는 경사하강법과 관련이 있음\n","              loss=\"sparse_categorical_crossentropy\",     #loss는 손실함수 > 점수가 낮아야 좋은 것(0에 가까워야 좋음)\n","              metrics=[\"accuracy\"])                       #얼마나 정확한지 > 점수가 높으면 좋은 것(1에 가까워야 좋음)\n","              #optimizer가 가중치의 기준을 찾을때 loss 함수를 기준으로 삼는다\n","              #metrics는 사람이 평가하기위해 사용(훈련할때는 불필요)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zpdBZcWJwibH"},"source":["**이미지 데이터 전처리**\n","\n","모델이 사용하기 좋은 방식으로 데이터셋의 표현을 0과 1사이의 값으로 구성된\n","2차원 어레이로 변환한다. \n","즉, 0부터 255 사이의 정수로 이루어진 `(28, 28)` 모양의 2차원 어레이로 표현된 이미지를\n","0부터 1 사이의 부동소수점으로 이루어진 `(28*28, )` 모양의 1차원 어레이로 변환한다.\n","\n","- 훈련 세트 어레이 모양: `(60000, 28*28)`\n","- 테스트 세트 어레이 모양: `(10000, 28*28)`"]},{"cell_type":"markdown","metadata":{"id":"TaQCZgGswibH"},"source":["<div align=\"center\"><img src=\"https://lh3.googleusercontent.com/LDpYKmElX5GwHgDwT2x2IyKMgUflP3cQ3ZiHuNCaf04b4AXwk04stNgr0-YymwJRFrxKpW9gxaxbYBnwyKflVVFGQ0kRYgsVDGgHFveaQRaBH5dxs78MgHkQvn5FHsjhZjIbj-WW2NI\" style=\"width:700px;\"></div>\n","\n","그림 출처: [생활코딩: 한 페이지 머신러닝](https://www.opentutorials.org/module/3653/22060)"]},{"cell_type":"code","metadata":{"id":"u_taRz5vwibH"},"source":["train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype(\"float32\") / 255   # 0과 1사이의 값 / 0~1의 값이 훈련을 더 잘하기 때문에 255로 나눔\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype(\"float32\") / 255     # 0과 1사이의 값"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLWjWelowibI"},"source":["**모델 훈련**\n","\n","컴파일된 객체 모델을 훈련한다. \n","\n","- `fit()` 메서드 호출: 훈련 세트와 레이블을 인자로 사용\n","- `epoths`: 에포크(전체 훈련 세트 대상 반복 훈련 횟수)\n","- `batch_size`: 가중치 업데이트 한 번 실행할 때 사용되는 샘플 수"]},{"cell_type":"code","metadata":{"id":"p4WENUMTwibI","outputId":"a50c6e39-b105-4a7e-ddbb-c41f1842cfdb"},"source":["model.fit(train_images, train_labels, epochs=5, batch_size=128) # batch_size=128는 미니배치를 사용\n","#6만개의 데이터를 128로 나눠서 훈련\n","#6만개의 샘플을 5번 확인\n","#손실값을 optimizer가 줄인것이다"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","469/469 [==============================] - 3s 3ms/step - loss: 0.4256 - accuracy: 0.8779\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9681\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9799\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9858\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9895\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x12a11ba1550>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"Jo55e411wibI"},"source":["훈련 세트 대상으로 최종 98.98%의 정확도 성능을 보인다."]},{"cell_type":"markdown","metadata":{"id":"5IqKHl5vwibI"},"source":["**모델 활용: 예측하기**\n","\n","훈련에 사용되지 않은 손글씨 숫자 이미지 10장에 대한 모델 예측값을 확인하기 위해\n","`predict()` 메서드를 이용한다."]},{"cell_type":"code","metadata":{"id":"9NVsm77xwibI"},"source":["test_digits = test_images[0:10]\n","predictions = model.predict(test_digits)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQPrtf9xwibI"},"source":["각 이미지에 대한 예측값은 이미지가 각 범주에 속할 확률을 갖는 \n","길이가 10인 1차원 어레이로 계산된다.\n","첫째 이미지에 대한 예측값은 다음과 같다."]},{"cell_type":"code","metadata":{"id":"TkbdBsEIwibJ","outputId":"01f8ba87-b237-4a70-a18a-fe641cee1fd7"},"source":["predictions[0]"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([2.2455287e-08, 1.1603313e-10, 4.6540663e-07, 1.8394494e-05,\n","       1.0458624e-12, 1.1035243e-08, 9.7097575e-14, 9.9997747e-01,\n","       6.3339858e-09, 3.7130744e-06], dtype=float32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"gQoq_xopwibJ"},"source":["가장 높은 확률값을 갖는 인덱스는 7이다."]},{"cell_type":"code","metadata":{"id":"gEgZ5GK2wibJ","outputId":"fffb9d56-6bcc-4283-d3e8-92b93ebf128d"},"source":["predictions[0].argmax()"],"execution_count":null,"outputs":[{"data":{"text/plain":["7"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"RuYBt_6GwibJ"},"source":["첫째 이미지가 가리키는 숫자가 7일 확률이 99.99%이다."]},{"cell_type":"code","metadata":{"id":"Vw-LEf_cwibJ","outputId":"b8c6ec14-71f7-4df2-e5d1-034f50638fd8"},"source":["predictions[0][7]"],"execution_count":null,"outputs":[{"data":{"text/plain":["0.99997747"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"SdyRDeYWwibJ"},"source":["실제로 첫째 이미지의 레이블이 7임을 확인할 수 있다."]},{"cell_type":"code","metadata":{"id":"656YMIfZwibJ","outputId":"e34180cb-c1ee-4c64-a73c-2543666298c4"},"source":["test_labels[0]"],"execution_count":null,"outputs":[{"data":{"text/plain":["7"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"b-YsVPa9wibK"},"source":["**테스트 성능**\n","\n","테스트 세트 전체에 대한 성능 평가는 `evaluate()` 메서드를 활용한다.\n","성능평가에 사용되는 지표는 앞서 모델을 컴파일할 때 지정한 정확도(accuracy)가 사용된다."]},{"cell_type":"code","metadata":{"id":"z7QRltsiwibK","outputId":"ba6582ae-8cef-4ffc-d3a6-722fea45d3c5"},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f\"test_acc: {test_acc}\")\n","#model.evaluate는 정확도를 기준으로 평가한다는 뜻이다\n","#model.evaluate는 튜플을 반환한다. 첫번째는 손실값, 두번째는 정확도를 알려준다"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 1s 1ms/step - loss: 0.0610 - accuracy: 0.9811\n","test_acc: 0.9811000227928162\n"]}]},{"cell_type":"markdown","metadata":{"id":"rVCXwiqRwibK"},"source":["테스트 세트에 대한 정확도는 98% 정도이며 훈련 세트에 대한 정확도 보다 낮다.\n","이는 모델이 훈련 세트에 __과대적합__(overfitting) 되었음을 의미한다. \n","과대적합에 대해서는 나중에 보다 자세히 다룰 것이다."]},{"cell_type":"markdown","metadata":{"id":"NVlHrj0ZwibK"},"source":["## 2.2 신경망에 사용되는 데이터 표현"]},{"cell_type":"markdown","metadata":{"id":"CJcwRsM2wibK"},"source":["앞서 __텐서__(tensor)라고 불리는 넘파이 어레이(NumPy array)를 이용하여\n","데이터를 표현하였다.\n","\n","텐서는 기본적으로 숫자를 담은 컨테이너(container)이며,\n","행렬의 경우 2 개의 차원으로 구성된 텐서로 표현된다. \n","텐서의 차원은 임의로 많을 수 있으며, 텐서에 사용되는 차원을 __축__(axis)이라 부르기도 한다. \n","차원의 수를 랭크(rank)라 부른다.\n","즉 행렬은 랭크가 2인 텐서이다.\n","\n","__주의사항__: tensorflow 라이브러리가 제공하는 `Tensor` 자료형은 NumPy의 어레이\n","자료형과 매우 비슷하다. 다만 `Tensor`는 GPU를 활용한 연산을 지원하고\n","넘파이 어레이는 그렇지 않다. \n","하지만 두 자료형 사이의 형변환이 존재하여 keras 모델 훈련 등 \n","필요할 때 적절한 형변환이 자동으로 이루어진다. "]},{"cell_type":"markdown","metadata":{"id":"Yy1JAzaXwibK"},"source":["### 스칼라(0D 텐서)\n","\n","숫자 하나로 이루어진 텐서를 __스칼라__(scalar)라고 하며,\n","차원이 없다는 의미에서 0D 텐서로 부른다. \n","넘파이의 경우 `float32`, `float64` 등이 스칼라이다."]},{"cell_type":"code","metadata":{"id":"YNdsGbmpwibK","outputId":"698ec4aa-26c9-4610-a412-ce2af2a47a2a"},"source":["import numpy as np\n","\n","x = np.array(12)\n","x"],"execution_count":null,"outputs":[{"data":{"text/plain":["array(12)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"dDQHlylSwibL"},"source":["텐서의 랭크는 `ndim` 속성이 가리킨다."]},{"cell_type":"code","metadata":{"id":"NricUuo2wibL","outputId":"bb31dfb8-b46a-4f81-f970-b4f780ce8d86"},"source":["x.ndim    #ndim으로 차원을 확인할 수 있다"],"execution_count":null,"outputs":[{"data":{"text/plain":["0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"64blpycDwibL"},"source":["### 벡터 (1D 텐서)\n","\n","벡터는 1개의 차원(축)을 갖는다. \n","넘파이의 경우 1차원 어레이가 벡터이다."]},{"cell_type":"code","metadata":{"id":"cExFFDJhwibL","outputId":"12d35ce5-047f-4748-ec30-71bec71c37fe"},"source":["# 1차원 리스트라고 생각하면 된다\n","x = np.array([12, 3, 6, 14, 7])\n","x"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([12,  3,  6, 14,  7])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"n9DV3KJKwibM","outputId":"f2db5f05-0613-4660-f35e-4295713b13f6"},"source":["x.ndim"],"execution_count":null,"outputs":[{"data":{"text/plain":["1"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"6UPnrr76wibM"},"source":["__주의사항__: __벡터의 길이__를 __차원__이라 부르기도 하는 점에 주의해야 한다.\n","예를 들어, 위 벡터는 5D 벡터이다. "]},{"cell_type":"markdown","metadata":{"id":"CvmriJx2wibM"},"source":["### 행렬(2D 텐서)\n","\n","행렬은 동일한 크기의 벡터로 이루어진 어레이며, \n","행(row)과 열(column) 두 개의 축을 갖는다. \n","넘파이의 2차원 어레이가 2D 텐서이다."]},{"cell_type":"code","metadata":{"id":"5rAHb_4nwibM"},"source":["x = np.array([[5, 78, 2, 34, 0],\n","              [6, 79, 3, 35, 1],\n","              [7, 80, 4, 36, 2]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kqn2UvqswibM","outputId":"041f1678-4053-4106-8b3a-6c035948e3c6"},"source":["x.ndim"],"execution_count":null,"outputs":[{"data":{"text/plain":["2"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"67RiaowLwibM"},"source":["### 3D 이상의 고차원 텐서\n","\n","2D 텐서로 이루어진 어레이가 3D 텐서이며,\n","이 과정을 반복해서 4D 이상의 고차원 텐서도 생성할 수 있다.\n","딥러닝에서 다루는 텐서는 보통 최대 4D이며,\n","동영상 데이터를 다룰 때 5D 텐서도 사용한다."]},{"cell_type":"code","metadata":{"id":"6VHLf-8wwibM"},"source":["x = np.array([[[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","              [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","              [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQat4crowibM","outputId":"8a09c8a6-429b-44c9-de7c-8b2e788d0df8"},"source":["x.ndim"],"execution_count":null,"outputs":[{"data":{"text/plain":["3"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"WE3kMt4XwibM"},"source":["### 텐서의 주요 속성\n","\n","\n","- 축의 수(랭크, `ndim`)\n","    - 텐서에 사용된 축(차원)의 개수\n","    - 음이 아닌 정수\n","- 모양(`shape`)\n","    - 각각의 축에 사용된 (벡터의) 차원 수\n","    - 정수로 이루어진 튜플\n","- 자료형(`dtype`)\n","    - 텐서에 사용된 항목들의 (통일된) 자료형\n","    - `float16`, `float32`,`float64`, `int8`, `string` 등이 가장 많이 사용됨.\n","    - 8, 16, 32, 64 등의 숫자는 해당 숫자를 다루는 데 필요한 메모리의 비트(bit) 크기를 가리킴.\n","        즉, 텐서에 사용되는 항목들을 일괄된 크기의 메모리로 처리함."]},{"cell_type":"markdown","metadata":{"id":"i--PxPlTwibN"},"source":["MNIST 훈련 세트를 대상으로 언급된 속성을 확인해보자.\n","앞서 모양을 변형하였기에 다시 원본 데이터를 불러온다."]},{"cell_type":"code","metadata":{"id":"jjtduUl5wibN"},"source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnlleY09wibN","outputId":"aecece5f-0bf7-4431-ac8f-a8bd06a51d80"},"source":["train_images.ndim"],"execution_count":null,"outputs":[{"data":{"text/plain":["3"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"ZqpnfUErwibN","outputId":"aa413549-a422-4017-c015-12e8f7c75570"},"source":["train_images.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(60000, 28, 28)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"6oW8noIywibN","outputId":"7510ec1d-ae69-4b99-83f9-fa10818233b8"},"source":["train_images.dtype"],"execution_count":null,"outputs":[{"data":{"text/plain":["dtype('uint8')"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"Ps-CLVKTwibN"},"source":["**다섯 번째 이미지 확인하기**"]},{"cell_type":"markdown","metadata":{"id":"GmA52093wibN"},"source":["훈련 세트에 포함된 이미지 중에서 다섯 번째 이미지를 직접 확인해보자.\n","이를 위해 pyplot 모듈의 `imshow()` 함수를 이용한다."]},{"cell_type":"code","metadata":{"id":"Hwrik5HPwibO","outputId":"d4303b0d-c2d2-4867-f52f-61cc02a39a2e"},"source":["import matplotlib.pyplot as plt\n","\n","digit = train_images[4]\n","plt.imshow(digit, cmap=plt.cm.binary)\n","plt.show()"],"execution_count":null,"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"cRtQfdAbwibO"},"source":["다섯 번째(4번 인덱스) 이미지는 실제로 숫자 9를 가리킨다."]},{"cell_type":"code","metadata":{"id":"etpQBf3zwibO","outputId":"a0bc3711-12bb-4245-d5b9-958013727519"},"source":["train_labels[4]"],"execution_count":null,"outputs":[{"data":{"text/plain":["9"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"dPLWCB9XwibO"},"source":["### 넘파이를 이용한 텐서 조작"]},{"cell_type":"markdown","metadata":{"id":"JhJGE1JQwibO"},"source":["#### 인덱싱(indexing)"]},{"cell_type":"markdown","metadata":{"id":"pzZNDM5-wibO"},"source":["텐서에 포함된 특정 인덱스의 항목 선택하려면 인덱싱을 사용한다. "]},{"cell_type":"code","metadata":{"id":"ouH0Dxr_wibO","outputId":"4ae6ef49-6499-4b9d-e24b-4152953f961d"},"source":["train_labels[4]"],"execution_count":null,"outputs":[{"data":{"text/plain":["9"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"gFmLPDh5wibO"},"source":["#### 슬라이싱"]},{"cell_type":"markdown","metadata":{"id":"zoueU75hwibO"},"source":["텐서에 포함된 특정 구간에 포함된 인덱스에 해당하는 항목으로 이루어진 텐서를\n","생성할 때 슬라이싱을 사용한다. "]},{"cell_type":"code","metadata":{"id":"4sAYz9y2wibO","outputId":"29b01e62-306f-4258-b79e-ef7326c0fe90"},"source":["my_slice = train_images[10:100]\n","my_slice.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(90, 28, 28)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"vGzbCpScwibP"},"source":["`:`는 지정된 축의 인덱스 전체를 대상으로 한다.\n","따라서 위 코드는 아래 두 코드와 동일한 기능을 수행한다."]},{"cell_type":"code","metadata":{"id":"5m7mGoOUwibP","outputId":"10e41806-ed55-46fc-cf53-b2b3f89e5547"},"source":["my_slice = train_images[10:100, :, :]\n","my_slice.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(90, 28, 28)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"WkXH09a4wibP","outputId":"cabc8d71-c2a1-4742-8293-cc5708ae679b"},"source":["my_slice = train_images[10:100, 0:28, 0:28]\n","my_slice.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(90, 28, 28)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"1oSWtbvuwibP"},"source":["이미지 전체를 대상으로 오른편 하단의 `14x14` 픽셀만 추출하려면 다음과 같이\n","슬라이싱을 진행한다."]},{"cell_type":"code","metadata":{"id":"hReyOHPLwibP"},"source":["my_slice = train_images[:, 14:, 14:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qUBhedFQwibP"},"source":["이미지 전체를 대상으로 중앙에 위치한 `14x14` 픽셀만 추출하려면 다음과 같이\n","슬라이싱을 진행한다.\n","음의 인덱스는 끝(-1번 인덱스)에서부터 역순으로 세어진 인덱스를 가리킨다."]},{"cell_type":"code","metadata":{"id":"-GES2G0hwibP"},"source":["my_slice = train_images[:, 7:-7, 7:-7]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VNA6YenwibP"},"source":["### 데이터 배치(묶음)\n","\n","케라스를 포함하여 대부분의 딥러닝 모델은 훈련 세트 전체를 한꺼번에 처리하지 않고\n","지정된 크기(`batch_size`)의 배치(batch)로 나주어 처리한다. \n","앞서 살펴본 모델의 배치 크기는 128이었다."]},{"cell_type":"markdown","metadata":{"id":"c0XiiRAdwibP"},"source":["#### 샘플 축 또는 샘플 차원\n","\n","딥러닝에 사용되는 모든 훈련 세트의 0번 축(axis 0)은 \n","포함된 샘플 각각을 가리키는 __샘플 축__(samples axis)이며, \n","__샘플 차원__(samples dimension)이라고도 불린다.\n","특별히 배치 텐서와 관련해서는 0번 축(axis 0)을\n","__배치 축__(batch axis) 또는 __배치 차원__(batch dimension)이라고 부른다."]},{"cell_type":"markdown","metadata":{"id":"41BXhTbuwibQ"},"source":["- 첫째 배치"]},{"cell_type":"code","metadata":{"id":"WEfSPLr_wibQ"},"source":["batch = train_images[:128]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpmDh_T8wibQ"},"source":["- 둘째 배치"]},{"cell_type":"code","metadata":{"id":"fvCuYP0vwibQ"},"source":["batch = train_images[128:256]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72DatYDiwibQ"},"source":["- n 번째 배치"]},{"cell_type":"code","metadata":{"id":"wENDvndVwibQ"},"source":["n = 3 # 임의의 n이라고 가정해야 함\n","\n","batch = train_images[128 * n:128 * (n + 1)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txgah9rAwibQ"},"source":["## 2.3 텐서 연산"]},{"cell_type":"markdown","metadata":{"id":"wM-mNHHBwibQ"},"source":["신경망 모델의 훈련은 기본적으로 텐서와 관련된 몇 가지 연산으로 이루어진다. \n","예를 들어 이전 신경망에 사용된 케라스 레이어를 살펴보자.\n","\n","```python\n","keras.layers.Dense(512, activation=\"relu\")\n","keras.layers.Dense(10, activation=\"softmax\")\n","```\n","\n","위 두 개의 층이 하는 일은 데이터셋의 변환이며 실제로 이루어지는 연산은 다음과 같다.\n","\n","- 1층\n","\n","    ```python\n","    output1 = relu(dot(input1, W1) + b1)\n","    ```\n","- 2층\n","\n","    ```python\n","    output2 = softmax(dot(input2, W2) + b2)\n","    ```\n","\n","- 점곱(`dot(input, W)`): 입력 텐서와 가중치 텐서의 곱\n","- 덧셈(`dot(input, W) + b`): 점곱의 결과 텐서와 벡터 `b`의 합\n","- `relu` 함수: `relu(x) = max(x, 0)`\n","- `softmax` 함수: 10개 범주 각각에 속할 확률 계산"]},{"cell_type":"markdown","metadata":{"id":"FV8gFed5wibQ"},"source":["<div align=\"center\"><img src=\"https://s3-ap-northeast-2.amazonaws.com/opentutorials-user-file/module/3653/9363.png\" style=\"width:700px;\"></div>\n","\n","그림 출처: [생활코딩: 한 페이지 머신러닝](https://www.opentutorials.org/module/3653/22060)"]},{"cell_type":"markdown","metadata":{"id":"CXRMz_A3wibQ"},"source":["### 항목별 연산\n","\n","넘파이의 어레이 연산처럼 텐서의 연산도 항목별로 이루어진다. \n","예를 들어, `relu()` 함수도 각 항목에 적용되며,\n","실제로 아래와 같이 구현할 수 있다."]},{"cell_type":"code","metadata":{"id":"XQ21vAipwibR"},"source":["def naive_relu(x):\n","    assert len(x.shape) == 2\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] = max(x[i, j], 0)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRrMhjQ1wibR"},"source":["덧셈도 동일하다."]},{"cell_type":"code","metadata":{"id":"bjWJWff0wibR"},"source":["def naive_add(x, y):\n","    assert len(x.shape) == 2\n","    assert x.shape == y.shape\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[i, j]\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rziOPbyswibR"},"source":["넘파이의 경우 항목별 연산을 병렬처리가 가능하며\n","매우 효율적으로 작동하는 저수준 언어로 구현되어 있다.\n","아래 두 코드는 넘파이를 활용할 때와 그렇지 않을 때의 \n","처리속도의 차이를 잘 보여준다."]},{"cell_type":"code","metadata":{"id":"zziLSD-owibR","outputId":"891887b6-3e57-481e-b657-76e244874246"},"source":["import time\n","\n","x = np.random.random((20, 100))\n","y = np.random.random((20, 100))\n","\n","t0 = time.time()\n","for _ in range(1000):\n","    z = x + y\n","    z = np.maximum(z, 0.)\n","print(f\"Took: {time.time() - t0:.2f}초\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Took: 0.00초\n"]}]},{"cell_type":"code","metadata":{"id":"1Ci-FC7BwibR","outputId":"2dd469c7-b7cf-499b-f2d7-5a2cee4426f6"},"source":["t0 = time.time()\n","for _ in range(1000):\n","    z = naive_add(x, y)\n","    z = naive_relu(z)\n","print(f\"Took: {time.time() - t0:.2f}초\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Took: 1.75초\n"]}]},{"cell_type":"markdown","metadata":{"id":"S3tY5bziwibR"},"source":["텐서플로우 또한 GPU로 병렬 처리를 효율적으로 수행하는 항목변 연산을 지원한다."]},{"cell_type":"markdown","metadata":{"id":"PiHYarY5wibR"},"source":["### 브로드캐스팅(Broadcasting)"]},{"cell_type":"markdown","metadata":{"id":"eF0kVLK-wibR"},"source":["아래 식은 2D 텐서와 벡터(1D 텐서)의 합을 계산한다.\n","\n","```python\n","dot(input, W) + b\n","```\n","\n","차원이 다른 텐서의 합과 차를 계산하려면 모양을 먼저 맞춰주어야 한다. \n","위 표현식의 계산과정에서 `b`를 먼저 `dot(input, W)`의 모양과 일치하도록\n","브로드캐스팅 한다."]},{"cell_type":"markdown","metadata":{"id":"7enuKJlkwibR"},"source":["아래 코드는 2D 텐서와 1D 텐서의 합이 이루어지는 과정을 보여준다."]},{"cell_type":"code","metadata":{"id":"LMOW_i99wibS"},"source":["import numpy as np\n","X = np.random.random((32, 10))\n","y = np.random.random((10,))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLuQI4eLwibS","outputId":"248df164-421b-4a80-b54a-6acedfb46607"},"source":["y"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([0.60657066, 0.59158708, 0.13459091, 0.79086762, 0.26130056,\n","       0.92265666, 0.04383687, 0.40154586, 0.38299812, 0.59109761])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"qQgphAp1wibS"},"source":["- `y` 텐서 2D로 변환: `(10,)` 모양의 1D 텐서를 `(1, 10)` 모양의 2D 텐서로 변환"]},{"cell_type":"code","metadata":{"id":"wS3mWSSawibS","outputId":"3a812987-cc50-4d9c-d392-8f6d751ee784"},"source":["y2 = np.expand_dims(y, axis=0)\n","y2"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([[0.60657066, 0.59158708, 0.13459091, 0.79086762, 0.26130056,\n","        0.92265666, 0.04383687, 0.40154586, 0.38299812, 0.59109761]])"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"KiERIzDuwibS"},"source":["- `(32, 10)` 모양의 2D 텐서로 변환: 0번 행을 32번 복사해서 추가"]},{"cell_type":"code","metadata":{"id":"s7_JJY8vwibS"},"source":["Y = np.concatenate([y2] * 32, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtdNR_AEwibS","outputId":"bf85b18f-3b01-481c-a48b-0c53dccdf145"},"source":["Y.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(32, 10)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"pPxmyRFGwibS","outputId":"3b2ac23a-c471-442f-b545-e2b59a997aa2"},"source":["((X + y) == (X + Y)).all()"],"execution_count":null,"outputs":[{"data":{"text/plain":["True"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"EgV5tsfzwibS"},"source":["이어지는 코드는 아래 형식의 브로드캐스팅을 직접 구현한다."]},{"cell_type":"markdown","metadata":{"id":"hXjYk072wibS"},"source":["<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/pydata/master/notebooks/images/broadcasting10.png\" style=\"width:400px;\"></div>"]},{"cell_type":"code","metadata":{"id":"s0exfggnwibT"},"source":["def naive_add_matrix_and_vector(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 1\n","    assert x.shape[1] == y.shape[0]\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[j]\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U8pRAV53wibT"},"source":["아래 코드는 차원이 다른 두 텐서에 대해 \n","항목별 최댓값을 계산하는 것이 \n","브로드캐스팅 덕분에 가능함을 보여준다."]},{"cell_type":"code","metadata":{"id":"6WxcPFMqwibT"},"source":["import numpy as np\n","x = np.random.random((64, 3, 32, 10))\n","y = np.random.random((32, 10))\n","z = np.maximum(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGt1oMJ1wibT"},"source":["### 텐서 점곱\n","\n","텐서의 점곱(dot product)은 차원에 따라 다른 계산을 수행한다. "]},{"cell_type":"markdown","metadata":{"id":"gHvuejMcwibT"},"source":["- 두 벡터의 점곱"]},{"cell_type":"code","metadata":{"id":"5QT3VdP0wibT","outputId":"85e97ebb-9481-45a6-9cbb-9c1d57041b36"},"source":["x = np.random.random((32,))\n","y = np.random.random((32,))\n","z = np.dot(x, y)\n","z"],"execution_count":null,"outputs":[{"data":{"text/plain":["7.896918974972176"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"0PLQkXq5wibT"},"source":["직접 구현하면 다음과 같다."]},{"cell_type":"code","metadata":{"id":"_sYw80YQwibT"},"source":["def naive_vector_dot(x, y):\n","    assert len(x.shape) == 1\n","    assert len(y.shape) == 1\n","    assert x.shape[0] == y.shape[0]\n","    z = 0.\n","    for i in range(x.shape[0]):\n","        z += x[i] * y[i]\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8a_3bfhwibT","outputId":"cac5d5e6-12b1-49cb-b47c-f53c6d856012"},"source":["naive_vector_dot(x, y)"],"execution_count":null,"outputs":[{"data":{"text/plain":["7.896918974972179"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"AD3wh6hPwibU"},"source":["- 2D 텐서와 벡터의 점곱 (방식 1)"]},{"cell_type":"code","metadata":{"id":"vLRruNjDwibU","outputId":"2a63655c-e7ab-4ee8-e39f-55b02250f707"},"source":["x = np.random.random((2,3))\n","y = np.random.random((3,))\n","z = np.dot(x, y)\n","z"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([1.08590952, 0.98942507])"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"lA1owb6PwibU"},"source":["def naive_matrix_vector_dot(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 1\n","    assert x.shape[1] == y.shape[0]\n","    z = np.zeros(x.shape[0])\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            z[i] += x[i, j] * y[j]\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKRC-mrpwibU","outputId":"aa4dfad2-0cbd-40b4-f30e-5f513206326e"},"source":["naive_matrix_vector_dot(x, y)"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([1.08590952, 0.98942507])"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3t26EEkIwibU"},"source":["- 2D 텐서와 벡터의 점곱 (방식 2)"]},{"cell_type":"code","metadata":{"id":"WyFuyUYIwibU"},"source":["def naive_matrix_vector_dot(x, y):\n","    z = np.zeros(x.shape[0])\n","    for i in range(x.shape[0]):\n","        z[i] = naive_vector_dot(x[i, :], y)\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6voG19imwibV","outputId":"ea548a46-bf59-45c7-be24-4748a1e3a482"},"source":["naive_matrix_vector_dot(x, y)"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([1.08590952, 0.98942507])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"_CKRmKEfwibW"},"source":["- 2D 텐서와 2D 텐서의 점곱 (행렬의 곱)"]},{"cell_type":"code","metadata":{"id":"8g6flT9WwibW","outputId":"b10ce5cf-cb4f-4c86-ea47-1f2e07d07b8d"},"source":["x = np.random.random((2,3))\n","y = np.random.random((3,4))\n","z = np.dot(x, y)\n","z"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([[0.97025084, 0.47286404, 1.37187905, 0.72199532],\n","       [1.4226074 , 0.97641969, 1.05230699, 0.44516051]])"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"mAhG-xbLwibW"},"source":["def naive_matrix_dot(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 2\n","    assert x.shape[1] == y.shape[0]\n","    z = np.zeros((x.shape[0], y.shape[1]))\n","    for i in range(x.shape[0]):\n","        for j in range(y.shape[1]):\n","            row_x = x[i, :]\n","            column_y = y[:, j]\n","            z[i, j] = naive_vector_dot(row_x, column_y)\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9UH4wm5wibW","outputId":"2eb8e6d8-559b-42bf-f3e8-3f0e239381a6"},"source":["naive_matrix_dot(x, y)"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([[0.97025084, 0.47286404, 1.37187905, 0.72199532],\n","       [1.4226074 , 0.97641969, 1.05230699, 0.44516051]])"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"RJok8gFWwibW"},"source":["### 텐서 모양 변환\n","\n","앞서 아래 코드에서 텐서의 모양을 변환했다. \n","\n","```python\n","train_images = train_images.reshape((60000, 28 * 28))\n","```\n","\n","즉, MNIST 훈련 세트가 원래 `(60000, 28, 28)` 모양의 3D 텐서로 주어졌는데\n","신경망 모델의 입력값으로 사용하기 위해 `(60000, 28 * 28)` 모양의 2D 텐서로 변환하는\n","전처리 과정을 사용했다. "]},{"cell_type":"code","metadata":{"id":"gcxyvf9RwibW"},"source":["train_images = train_images.reshape((60000, 28 * 28))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6fWDHh84wibW"},"source":["텐서의 모양 변환은 지정된 모양의 텐서를 생성하기 위해\n","기존 텐서의 행(row)과 열(column)을 새롭게 정렬한다.\n","따라서 항목의 개수는 변하지 않는다.\n","아래 코드는 텐서의 모양 변환을 설명하는 간단한 예제를 보여준다."]},{"cell_type":"code","metadata":{"id":"XzFxTkwuwibW","outputId":"a96a21ec-1ba9-49c6-96d7-3828ea0af577"},"source":["x = np.array([[0., 1.],\n","             [2., 3.],\n","             [4., 5.]])\n","x.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(3, 2)"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"5cWKabUpwibX","outputId":"4af17547-09fb-41a3-ede3-1c05183f1c79"},"source":["x = x.reshape((6, 1))\n","x"],"execution_count":null,"outputs":[{"data":{"text/plain":["array([[0.],\n","       [1.],\n","       [2.],\n","       [3.],\n","       [4.],\n","       [5.]])"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"d2tkw1i8wibX"},"source":["#### 행렬의 전치\n","\n","행렬(2D 텐서)의 행과 열을 바꾸는 __전치__(transposition) 또한 행렬의 모양 변환이다."]},{"cell_type":"code","metadata":{"id":"dnr5erv1wibX","outputId":"cf7658b9-1337-493d-820a-da58a38c4cfd"},"source":["x = np.zeros((300, 20))\n","x = np.transpose(x)\n","x.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(20, 300)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"loccRU6_wibX"},"source":["## 2.4 신경망의 엔진: 그레이디언트 기반 최적화"]},{"cell_type":"markdown","metadata":{"id":"8-VI8UzMwibX"},"source":["### 텐서플로우의 그레이디언트 테이프\n","\n","- 미분 자동화: 텐서플로우 등이 역전파에 필요한 미분을 자동으로 해결해줌. \n","- __그레이디언트 테이프__(gradient tape): 임의의 텐서 연산에 대해 원하는 변수에 대한\n","    그레이디언트를 미리 계산해서 기억해두는 독립적인 장치\n","- `tf.Variable` 객체: 그레이디언트 테이프를 사용하려면 변수를 `tf.Variable` 클래스의 \n","    인스턴스로 선언해야 함."]},{"cell_type":"markdown","metadata":{"id":"69aibaxVwibX"},"source":["#### 하나의 변수에 대한 그레이디언트"]},{"cell_type":"code","metadata":{"id":"Of-nugKDwibX"},"source":["import tensorflow as tf\n","x = tf.Variable(0.)               #미분값을 알고 싶으면 x = tf.Variable(0.) 이렇게 x를 tf로 선언해줘야한다!\n","with tf.GradientTape() as tape:\n","    y = 2 * x + 3\n","grad_of_y_wrt_x = tape.gradient(y, x)   #미분"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMAYuotswibX","outputId":"c9405d3a-8779-4105-8301-d075ef15f792"},"source":["grad_of_y_wrt_x"],"execution_count":null,"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"sY0dJMl-wibX"},"source":["#### 임의의 텐서 연산에 대한 그레이디언트"]},{"cell_type":"markdown","metadata":{"id":"_yattc07kJhL"},"source":["임의의 n차원 array에 대해서도 가능하다"]},{"cell_type":"code","metadata":{"id":"5bqsUmTUwibX"},"source":["x = tf.Variable(tf.random.uniform((2, 2)))\n","with tf.GradientTape() as tape:\n","    y = 2 * x + 3\n","grad_of_y_wrt_x = tape.gradient(y, x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfuExWOgwibY","outputId":"48435a88-3414-4797-d090-0734b85e7ef4"},"source":["grad_of_y_wrt_x"],"execution_count":null,"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[2., 2.],\n","       [2., 2.]], dtype=float32)>"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"oY2ncT-lwibY"},"source":["#### 변수들의 리스트에 대한 그레이언트"]},{"cell_type":"code","metadata":{"id":"s1T0jRg1wibY"},"source":["W = tf.Variable(tf.random.uniform((2, 2)))\n","b = tf.Variable(tf.zeros((2,)))\n","x = tf.random.uniform((2, 2))\n","with tf.GradientTape() as tape:\n","    y = tf.matmul(x, W) + b   #편향값도 붙어야 한다\n","grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxrF---BwibY","outputId":"518f6b48-12cc-48cf-d4ab-8b123f5e2ac0"},"source":["grad_of_y_wrt_W_and_b"],"execution_count":null,"outputs":[{"data":{"text/plain":["[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n"," array([[0.53107774, 0.53107774],\n","        [0.9789088 , 0.9789088 ]], dtype=float32)>,\n"," <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"OO6JSuOjwibY"},"source":["## 2.5 신경망 구현: 밑바닥부터"]},{"cell_type":"markdown","metadata":{"id":"CvRXcFVGwibY"},"source":["케라스가 아닌 순수 텐서플로우 API 만을 이용해서\n","앞서 사용한 MINST 분류 신경망 모델에\n","사용된 클래스를 직접 구현한다. "]},{"cell_type":"markdown","metadata":{"id":"-JtrmFkzwibY"},"source":["### MNIST 케라스 모델\n","\n","앞서 사용한 케라스 모델과 훈련 과정은 다음과 같다."]},{"cell_type":"code","metadata":{"id":"m2t80giCwibY"},"source":["(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype(\"float32\") / 255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKzX34GOwibY"},"source":["model = keras.Sequential([                          #Sequential 여러 단계를 거쳐서 하는 방법이다\n","    layers.Dense(512, activation=\"relu\"),           \n","    layers.Dense(10, activation=\"softmax\")\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTA6xw8OwibY"},"source":["model.compile(optimizer=\"rmsprop\",                 #rmsprop가 역전파 알고리즘이다\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usYPtSCdwibY","outputId":"ef4dab65-2db2-4989-953d-6cbe5587222f"},"source":["model.fit(train_images, train_labels, epochs=5, batch_size=128)\n","#6만개를 128개의 묶음으로 쪼개고, 하나의 배치에 대해서 훈련하고 128개에 대해서 예측을하고 실제 타겟값과 비교해서 오차를 계산함\n","#미니배치(몇십개에서 몇백개만 묶음)\n","#이과정을 통해 손실함수를 줄여나가고 가장 예측을 잘하는 가중치를 찾아나감\n","#이과정을 통틀어 학습이라고 한다"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4376 - accuracy: 0.8717\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1100 - accuracy: 0.9677\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9802\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9850\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9889\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x12a14fe1b80>"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"cvsMofNHwibZ"},"source":["### 텐서플로우만을 사용한 MNIST 모델 구현"]},{"cell_type":"markdown","metadata":{"id":"9YVrIHJtwibZ"},"source":["#### 단순한 `Dense` 클래스"]},{"cell_type":"code","metadata":{"id":"HuxgvQrdwibZ"},"source":["import tensorflow as tf\n","\n","class NaiveDense:\n","    def __init__(self, input_size, output_size, activation):\n","        self.activation = activation\n","\n","        w_shape = (input_size, output_size)\n","        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n","        self.W = tf.Variable(w_initial_value)\n","\n","        b_shape = (output_size,)\n","        b_initial_value = tf.zeros(b_shape)\n","        self.b = tf.Variable(b_initial_value)\n","\n","    def __call__(self, inputs):\n","        return self.activation(tf.matmul(inputs, self.W) + self.b)\n","\n","    @property\n","    def weights(self):\n","        return [self.W, self.b]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cn-_2L6IwibZ"},"source":["#### 단순한 `Sequential` 클래스"]},{"cell_type":"code","metadata":{"id":"qrLs0mqdwibZ"},"source":["class NaiveSequential:\n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, inputs):\n","        x = inputs\n","        for layer in self.layers:\n","           x = layer(x)\n","        return x\n","\n","    @property\n","    def weights(self):\n","       weights = []\n","       for layer in self.layers:\n","           weights += layer.weights\n","       return weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZlkshVuwibZ"},"source":["model = NaiveSequential([\n","    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n","    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n","])\n","assert len(model.weights) == 4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_wy8A-iSwibZ"},"source":["#### 배치(묶음) 생성기"]},{"cell_type":"code","metadata":{"id":"9APhu4erwibZ"},"source":["import math\n","\n","class BatchGenerator:\n","    def __init__(self, images, labels, batch_size=128):\n","        assert len(images) == len(labels)\n","        self.index = 0\n","        self.images = images\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.num_batches = math.ceil(len(images) / batch_size)\n","\n","    def next(self):\n","        images = self.images[self.index : self.index + self.batch_size]\n","        labels = self.labels[self.index : self.index + self.batch_size]\n","        self.index += self.batch_size\n","        return images, labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3yCqxe2Iwiba"},"source":["### 훈련 단계\n","\n","하나의 데이터 배치를 학습한 후에 가중치를 업데이트하는 기능을 수행하는 함수를 정의한다."]},{"cell_type":"code","metadata":{"id":"Zy4ASZFKwiba"},"source":["def one_training_step(model, images_batch, labels_batch):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images_batch)\n","        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n","            labels_batch, predictions)\n","        average_loss = tf.reduce_mean(per_sample_losses)\n","    gradients = tape.gradient(average_loss, model.weights)\n","    update_weights(gradients, model.weights)   # 가중치 업데이트 함수. \n","    \n","    return average_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jkj7DIrVwiba"},"source":["가중치 업데이트 함수는 다음과 같다."]},{"cell_type":"code","metadata":{"id":"rpzLfcPtwiba"},"source":["learning_rate = 1e-3\n","\n","def update_weights(gradients, weights):\n","    for g, w in zip(gradients, model.weights):\n","        w.assign_sub(g * learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hRLaesYLwiba"},"source":["__주의사항__: 가중치 업데이트 함수를 직접 구현하는 일은 매우 드물 것이다.\n","대신에 케라스의 `Optimizer` 인스턴스를 사용할 것을 권장한다.\n","예를 들어 아래 코드는 `SGD` 옵티마이저를 사용한다."]},{"cell_type":"code","metadata":{"id":"BWzELxLwwiba"},"source":["from tensorflow.keras import optimizers\n","\n","optimizer = optimizers.SGD(learning_rate=1e-3)\n","\n","def update_weights(gradients, weights):\n","    optimizer.apply_gradients(zip(gradients, weights))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fDT_osfewiba"},"source":["### 훈련 반복: 모델 학습"]},{"cell_type":"code","metadata":{"id":"O3KAkqxBwiba"},"source":["def fit(model, images, labels, epochs, batch_size=128):\n","    for epoch_counter in range(epochs):\n","        print(f\"Epoch {epoch_counter}\")\n","        batch_generator = BatchGenerator(images, labels)\n","        for batch_counter in range(batch_generator.num_batches):\n","            images_batch, labels_batch = batch_generator.next()\n","            loss = one_training_step(model, images_batch, labels_batch)\n","            if batch_counter % 100 == 0:\n","                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfqHPuGewiba","outputId":"276c4be8-1090-4237-9611-8fe578830239"},"source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype(\"float32\") / 255\n","\n","fit(model, train_images, train_labels, epochs=10, batch_size=128)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n","loss at batch 0: 4.42\n","loss at batch 100: 2.23\n","loss at batch 200: 2.19\n","loss at batch 300: 2.09\n","loss at batch 400: 2.22\n","Epoch 1\n","loss at batch 0: 1.92\n","loss at batch 100: 1.88\n","loss at batch 200: 1.82\n","loss at batch 300: 1.72\n","loss at batch 400: 1.83\n","Epoch 2\n","loss at batch 0: 1.60\n","loss at batch 100: 1.58\n","loss at batch 200: 1.50\n","loss at batch 300: 1.43\n","loss at batch 400: 1.52\n","Epoch 3\n","loss at batch 0: 1.34\n","loss at batch 100: 1.35\n","loss at batch 200: 1.24\n","loss at batch 300: 1.21\n","loss at batch 400: 1.28\n","Epoch 4\n","loss at batch 0: 1.14\n","loss at batch 100: 1.16\n","loss at batch 200: 1.05\n","loss at batch 300: 1.05\n","loss at batch 400: 1.12\n","Epoch 5\n","loss at batch 0: 0.99\n","loss at batch 100: 1.03\n","loss at batch 200: 0.91\n","loss at batch 300: 0.93\n","loss at batch 400: 1.00\n","Epoch 6\n","loss at batch 0: 0.88\n","loss at batch 100: 0.92\n","loss at batch 200: 0.81\n","loss at batch 300: 0.84\n","loss at batch 400: 0.91\n","Epoch 7\n","loss at batch 0: 0.80\n","loss at batch 100: 0.83\n","loss at batch 200: 0.73\n","loss at batch 300: 0.77\n","loss at batch 400: 0.84\n","Epoch 8\n","loss at batch 0: 0.73\n","loss at batch 100: 0.76\n","loss at batch 200: 0.67\n","loss at batch 300: 0.71\n","loss at batch 400: 0.79\n","Epoch 9\n","loss at batch 0: 0.68\n","loss at batch 100: 0.71\n","loss at batch 200: 0.62\n","loss at batch 300: 0.67\n","loss at batch 400: 0.74\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y2_rVPCfwibb"},"source":["### 모델 평가"]},{"cell_type":"code","metadata":{"id":"7hWbwForwibb","outputId":"d2fdb69a-c57a-4e7c-9bfa-ab946e99efdd"},"source":["predictions = model(test_images)\n","predictions = predictions.numpy()\n","predicted_labels = np.argmax(predictions, axis=1)\n","matches = predicted_labels == test_labels\n","print(f\"accuracy: {matches.mean():.2f}\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy: 0.81\n"]}]}]}